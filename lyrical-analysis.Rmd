---
title: "Lyrical Analysis"
output:
  pdf_document: default
  html_document: default
date: "2025-03-15"
--- 
# Load Libraries 
```{r}
library(class)
library(tm)
library(MASS)
library(nnet)
library(tidyverse)
library(tidyr)
library(caret)
library(tidytext)
library(olsrr)
```
# Load Data
```{r}
# Read Lines
lines <- readLines("lyran.csv", encoding = "UTF-8", warn = FALSE)
## Incomplete Final Line Warning
# Get only valid lines
cleaned_lines <- iconv(lines, from = "UTF-8", to = "UTF-8", sub = "byte")
valid_lines <- cleaned_lines[!is.na(cleaned_lines)]
# Write Cleaned to New File
writeLines(valid_lines, "lyran_cleaned.csv")

# Read the Cleaned File
lyrics_data <- read.csv("lyran_cleaned.csv", fileEncoding = "UTF-8", stringsAsFactors = FALSE)
```
# Stop Words and Cleaning Data
```{r}
# Define your custom stop words
custom_stopwords <- c("ah", "im", "ohohoh", "oo", "uhhuh", "nooh", "s", "yearold", "thatll", "hadnt", "theyve", "imma", "aint", "will", "gonna", "hes", "put", "cant","youve", "youd", "ill", "lets", "can", "ive", "got", "wouldve", "thats", "theyre", "youll", "oh", "dont", "id", "cottontail", "said", "youre", "get", "ooh", "ooooh", "aaaaaaahhhhhh", "aah", "aahooh", "ac", "ahahahahah", "ahh", "ai", "im", "abrams", "abramscagracie")
# Combine custom stopwords with the default (english) stop words
all_stopwords <- c(stopwords("en"), custom_stopwords)
corpus <- Corpus(VectorSource(lyrics_data$lyrics))
# Clean the corpus
corpus_clean <- corpus %>%
  tm_map(tolower) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(removeWords, all_stopwords) %>%
  tm_map(stripWhitespace)

tidy_lyrics <- data.frame(
  name = rep(lyrics_data$name, each = sapply(corpus_clean, length)),
  artist = rep(lyrics_data$artist, each = sapply(corpus_clean, length)),
  theme = rep(lyrics_data$theme, each = sapply(corpus_clean, length)),
  text = sapply(corpus_clean, as.character),
  row_id = seq_along(lyrics_data$name),  # Track the original row order
  stringsAsFactors = FALSE
)
```
# Reformatting Data
```{r}
# Make Unique Song_Artist_Id
lyrics_data <- tidy_lyrics %>%
  mutate(song_artist_id = paste(name, artist, sep = " ")) %>%
  dplyr::select(song_artist_id, theme, text)
```
# Count Words
```{r}
lyrics_data_tokens <- lyrics_data %>% 
  mutate(text = as.character(text)) %>% # Ensure text is character
  unnest_tokens(output = word, input = text) %>% # Tokenize
  group_by(song_artist_id, theme, word) %>% 
  summarise(word_count = n(), .groups = "drop") # Count words

```
# Pivot 
```{r}
lyrics_data_wide <- lyrics_data_tokens %>%
  pivot_wider(names_from = word, 
              values_from = word_count,  # Use word_indicator instead of word_count
              values_fill = 0,  # Fill missing values with 0
              names_glue = "word_{word}",  # Custom column naming for words
              names_repair = "unique")  # Make column names unique

```
# Normalize Within Column
```{r}
# Normalize each word column within the column (Min-Max Scaling)
lyrics_data_normalized <- lyrics_data_wide %>%
  mutate(across(starts_with("word_"), ~ (. - min(.)) / (max(.) - min(.)), .names = "norm_{.col}")) %>%
  dplyr::select(-starts_with("word_"))
```

# Log Transform Then Do Within Column
```{r}
lyrics_data_log_norm <- lyrics_data_wide %>%
  mutate(across(starts_with("word_"), ~ log(. + 1))) %>%  # Log-transform
  mutate(across(starts_with("word_"), ~ (. - min(.)) / (max(.) - min(.))))  # Normalize

```
# Pivot Theme
```{r}
lyrics_theme_binary <- lyrics_data_tokens %>%
  group_by(song_artist_id, theme) %>%
  summarise(theme_indicator = 1, .groups = "drop")
lyrics_theme_onehot <- lyrics_theme_binary %>%
  pivot_wider(
    names_from = theme,
    values_from = theme_indicator,
    values_fill = 0,
    names_glue = "{theme}_theme" # Custom column naming for themes
  )
```
```{r}
lyrics_data_log_norm <- as.data.frame(lyrics_data_log_norm)

lyrics_data_log_norm_factor <- lyrics_data_log_norm %>% mutate(theme_as_factor = factor(theme, ordered = FALSE))
```
```{r}
lyrics_combined <- full_join(lyrics_theme_onehot, lyrics_data_log_norm_factor, by = join_by(song_artist_id)) %>% dplyr::select(!theme)
```
# Filter to Help Pick Words
```{r}
lyrics_data_log_norm %>%
  filter(theme == "age/power dynamic") %>%  # Filter for the 'age/power dynamic' theme
  pivot_longer(cols = -c(song_artist_id, theme), names_to = "word", values_to = "value") %>%  # Pivot to long format (exclude song_artist_id and theme columns)
  filter(value > 0) %>%  # Only include rows where the word appears (value > 0)
  group_by(song_artist_id, word) %>%
  summarise(word_value_in_song = sum(value), .groups = "drop") %>%  # Count how many times the word appears in each unique song
  group_by(word) %>%
  summarise(
    total_word_value = sum(word_value_in_song), # Total word occurrences across all songs
    sd = sd(word_value_in_song),
    unique_songs = n_distinct(song_artist_id),  # Number of unique songs the word appears in
    .groups = "drop"
  ) %>%
  filter(unique_songs>1) %>%
  arrange(desc(total_word_value))  # Sort by total word count in descending order
```


# Testing and Training Data
```{r}
lyrics_data_log_norm_factor <- as.data.frame(lyrics_data_log_norm_factor)
lc_size <- floor(0.75 * nrow(lyrics_combined))

# Set Seed
set.seed(200)
train_ind_lc <- sample(seq_len(nrow(lyrics_combined)), size = lc_size)

train_lc <- lyrics_combined[train_ind_lc, ]
test_lc <- lyrics_combined[-train_ind_lc, ]

train_ldn <- lyrics_data_log_norm_factor[train_ind_lc, ]
test_ldn <- lyrics_data_log_norm_factor[-train_ind_lc, ]


```
# LDA Fit
```{r}
lda.fit <- lda(theme_as_factor ~ word_afford, data = lyrics_data_log_norm_factor, subset = train_ind_lc)
#print(lda.fit)
```
# LDA Results
```{r}
lda.pred <- predict(lda.fit, newdata = test_ldn)
lda.class <- lda.pred$class
lda_matrix <- table(Predicted = lda.class, Actual = test_ldn$theme_as_factor)
#print(lda_matrix)
actual_classes <- test_ldn$theme_as_factor
accuracy <- mean(lda.class == actual_classes)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
conf_matrix <- table(Predicted = lda.class, Actual = actual_classes)
#print(conf_matrix)
theme_accuracies <- diag(conf_matrix) / rowSums(conf_matrix)
theme_accuracies <- round(theme_accuracies * 100, 2)  # Convert to percentage
print(theme_accuracies)
```
```{r}
write.csv(lyrics_combined, "lyrics_combined.csv")
```

```{r}

```

# Testing Words
```{r}
word_lm <- lm(word_yeah ~ `age/power dynamic_theme` + rebellion_theme + love_theme + `moving on_theme` + growth_theme + situationship_theme + partying_theme + heartbreak_theme + `mental health_theme` + jealousy_theme + religion_theme + hate_theme + unrequited_theme + crush_theme + revenge_theme + revenge_theme + empowerment_theme + happy_theme + grief_theme + exes_theme + reminiscing_theme + `toxic relationship_theme` + `growing up_theme` + `forbidden love_theme`, data = lyrics_combined)
anova_result <- anova(word_lm)
anova_summary <- broom::tidy(anova_result)
# Filter only significant variables (p-value < 0.05)
significant_results <- anova_summary %>%
  arrange(p.value) %>%
  filter(p.value < 0.0001) 
# Display results
print(significant_results)
```
# Feature Selection
## Correlation Based Feature Selection
```{r}
#X <- train_lc[,-c(1:24,7332)]
#Y <- train_lc$theme_as_factor
```

## Recursive Feature Elmination
```{r}
#control <- rfeControl(functions = rfFuncs, method = "cv", number = 5)
#rfe_result <- rfe(X, Y, sizes = c(1:10), rfeControl = control)

# Selected features
#X_selected <- X[, predictors(rfe_result)]
```


```{r}
# Remove them
#X_filtered <- X[, -highly_correlated]
```

# Multi Log
```{r}
multi_log_model <- multinom(theme_as_factor ~ word_love + word_baby + 
    word_yeah + word_still + word_never, 
                            data = train_lc, trace = FALSE)
multi_log_pred <- predict(multi_log_model)#, newdata = test_lc)
# Calculate Accuracy
accuracy <- mean(multi_log_pred == train_lc$theme_as_factor)
print(paste("Multinomial Logistic Regression Accuracy:", round(accuracy * 100, 2), "%"))
# Create Confusion Matrix
conf_matrix <- table(Predicted = multi_log_pred, Actual = train_lc$theme_as_factor)
# Compute Accuracy per Theme (Diagonal / Row Sum)
theme_accuracies <- diag(conf_matrix) / rowSums(conf_matrix)
theme_accuracies <- round(theme_accuracies * 100, 2)  # Convert to percentages
# Print Theme-Wise Accuracy
print(theme_accuracies)
```
```{r}
# Calculate column sums
word_sums <- colSums(train_lc[, grepl("^word_", colnames(train_lc))])

# Select columns where sum is at least 2
selected_words <- names(word_sums[word_sums >= 35])

# Subset dataset with only selected word features + target variable
train_lc_filtered <- train_lc[, c("theme_as_factor", selected_words)]
```


```{r}
#full_model <- multinom(theme_as_factor ~ ., data = train_lc_filtered, trace = FALSE)
#step_model <- stepAIC(full_model, direction = "backward", trace = TRUE)

#summary(step_model)  # View selected variables
```


```{r}
df_metrics <- read_csv("~/Desktop/SDS 293 Data (Copy of MTH 354) /Machine Learning/MTH 354 Work.csv")
```
```{r}
df <- left_join(lyrics_combined, df_metrics, by = join_by(song_artist_id == name_artist), keep = TRUE)
write.csv(df, "df.csv")
# df3[complete.cases(df3),]
df <- df[complete.cases(df),]
df_num_syd <- df %>% select(!c(`...1`, Artist_Simplified, Song, Genre_Simplified, Unknown, Becca, Cathy, Emily, Lara, Lauren, Lily, Sorel, Melissa, Tyler, Kristin, Lindsey, song_artist_id))

df_num_syd <- df_num_syd %>% 
  select(where(is.numeric)) %>% 
  select(where(~sum(.) > 25))
```

```{r}
sydney <- lm(Sydney ~ ., df_num_syd) 
# stepwise forward regression
syd_forward_var <- ols_step_forward_p(sydney)
syd_forward_var
plot(syd_forward_var)
```


```{r}
syd_lm <- lm(Sydney ~ Dates_New + Popularity + Acoustic + unrequited_theme + word_never + word_know + Energy + word_go + word_like + word_make + Happy + word_take + word_wanna + Popularity, df_num_syd)
syd_lm
anova(syd_lm)
```


```{r, eval = FALSE, echo = FALSE}
ggplot(df_num_syd, aes(x = Dates_New, y = Sydney)) + 
  geom_point(aes(x = Dates_New, y = Sydney), color = "red") +
  geom_point(aes(x = Dates_New, y = Sydney), color = "orange") + 
  geom_point(aes(x = Acoustic, y = Sydney), color = "yellow") +
  geom_smooth(aes(x = Dates_New, y = Sydney), color = "red") +
  geom_smooth(aes(x = Popularity, y = Sydney), color = "orange") + 
  geom_smooth(aes(x = Acoustic, y = Sydney), color = "yellow") +
  geom_smooth(aes(x = word_never, y = Sydney), color = "green") 
```
```{r}
# stepwise backward regression
syd_backward_var <- ols_step_backward_p(sydney)
syd_backward_var
plot(syd_backward_var)
```
```{r}
syd_backward_lm <- lm(Sydney ~ Dates_New + Popularity + Acoustic + unrequited_theme + word_never + word_know + Energy + word_go + word_like + word_make + Happy + word_take + word_wanna + Popularity, data = df_num_syd)
syd_backward_lm
df_pred_syd <- predict(syd_backward_lm, newdata = df_num_syd) 
df_pred_syd <- df_num_syd %>% mutate(pred = df_pred_syd)
# First, make sure you have row identifiers to join by
df_pred_syd$song_index <- rownames(df)
df$song_index <- rownames(df)  # assumes rows were not reordered between df and df_num_syd

# Now join the predictions back to the original df
df_syd_songs <- left_join(df_pred_syd, df, by = "song_index")
df_syd_songs <- df_syd_songs %>% select(Song, Artist_Simplified, theme_as_factor, Genre_Simplified, Sydney.x, pred)

anova(syd_backward_lm)
```

```{r}
df_syd_songs %>% group_by(Sydney.x) %>% summarise(n=n(),
                                                 mean=mean(pred),
                                                 sd = sd(pred))
```
```{r}
df_with_songs <- df_syd_songs %>% 
  mutate(pred_ind = 0)

df_with_songs$pred_ind[df_with_songs$pred > mean(df_with_songs$Sydney.x)] <- 1
df_with_songs %>% group_by(Sydney.x, pred_ind) %>% summarise(n = n())
df_with_songs <- df_with_songs %>% mutate(correct = 0)

df_with_songs$correct[df_with_songs$Sydney.x==df_with_songs$pred_ind] <- 1

df_with_songs %>% group_by(Sydney.x, pred_ind, correct) %>% summarise(n = n())
tot_syd <- sum(df_with_songs$correct)/nrow(df_with_songs)
yes_syd <- sum(df_with_songs$correct[df_with_songs$Sydney.x == 1]) /sum(df_with_songs$Sydney.x)
no_syd <- sum(df_with_songs$correct[df_with_songs$Sydney.x == 0])/sum(df_with_songs$Sydney.x==0)

```


```{r}
syd_full <- df_metrics %>% filter(Sydney == 1)

syd_full %>% group_by(name_artist) %>% summarise(n=n(),
                                                    #  en = mean(Energy),
                                                 stat = mean(Happy)) %>% arrange(desc(stat)) %>% head(10)

```
```{r}
ggplot(df_pred_syd, aes(x = Dates_New, y = pred)) + 
  geom_point(aes(x = Dates_New, y = pred), color = "brown") + 
  geom_smooth(aes(x = Dates_New, y = pred), color = "brown") +
  geom_point(aes(x = Popularity, y = pred), color = "red") + 
  geom_smooth(aes(x = Popularity, y = pred), color = "red") +
  geom_point(aes(x = Acoustic, y = pred), color = "orange") + 
  geom_smooth(aes(x = Acoustic, y = pred), color = "orange") +
  geom_point(aes(x = word_never, y = pred), color = "yellow") + 
  geom_smooth(aes(x = word_never, y = pred), color = "yellow") +
  geom_point(aes(x = word_know, y = pred), color = "lightyellow") + 
  geom_smooth(aes(x = word_know, y = pred), color = "lightyellow") +
  geom_point(aes(x = Energy, y = pred), color = "lightgreen") + 
  geom_smooth(aes(x = Energy, y = pred), color = "lightgreen") +
  geom_point(aes(x = word_go, y = pred), color = "forestgreen") + 
  geom_smooth(aes(x = word_go, y = pred), color = "forestgreen") +
  geom_point(aes(x = word_like, y = pred), color = "darkgreen") + 
  geom_smooth(aes(x = word_like, y = pred), color = "darkgreen")
```

```{r}
#df_syd_songs %>% group_by(theme_as_factor, Sydney.x)  filter(Sydney.x ==0) %>% arrange(desc(pred))

df_syd_songs %>% filter(Sydney.x == 0) %>% select(Song, Artist_Simplified, pred) %>% arrange(desc(pred))
```

```{r}
df_num_full <- df %>% select(!c(`...1`, Artist_Simplified, Song, Genre_Simplified, Unknown, Becca, Cathy, Sydney, Emily, Lara, Lauren, Lily, Sorel, Melissa, Tyler, Kristin, Lindsey, song_artist_id))
names(df_num_full) <- gsub(" ", "_", names(df_num_full))
df_num_full_pred <- df_num_full
df_num_full_unreq <- df_num_full %>% 
  select(where(is.numeric)) %>% 
  select(c(where(~sum(.) > 25)), `unrequited_theme`)
  #select(!c(crush_theme, empowerment_theme, exes_theme, `forbidden love_theme`, grief_theme, `growing up_theme`, growth_theme, happy_theme,hate_theme, heartbreak_theme, jealousy_theme, love_theme,`mental health_theme`,`moving on_theme`, partying_theme,rebellion_theme, religion_theme, reminiscing_theme, revenge_theme,situationship_theme, `toxic relationship_theme`,unrequited_theme))
df_num_full_situ <- df_num_full %>% 
  select(where(is.numeric)) %>% 
  select(c(`situationship_theme`,where(~sum(.) > 15)))
```
```{r}
unreq <- lm(`unrequited_theme` ~ ., data = df_num_full_unreq)
unreq_backward_var <- ols_step_backward_p(unreq)
#unreq_backward_var
#plot(syd_backward_var)
```

```{r}
unreq_backwards <- lm(unrequited_theme ~ Rock + Loud + Popularity + word_go + word_let, df_num_full_unreq)
anova(unreq_backwards)
unreq_pred <- predict(unreq_backwards, newdata = df_num_full)
df_num_full_pred$unreq_pred <- unreq_pred
#plot(unreq_backward_var)
```

```{r}
situ <- lm(`situationship_theme` ~ ., data = df_num_full_situ)
situ_backward_var <- ols_step_backward_p(situ)
#situ_backward_var
```


```{r}
situ_backwards <- lm(situationship_theme ~ word_call + word_just + word_much + word_one + word_baby+   word_eyes + word_hold + word_life + word_right + word_enough + word_let, data = df_num_full_situ)
anova(situ_backwards)
situ_pred <- predict(situ_backwards, newdata = df_num_full)
df_num_full_pred$situ_pred <- situ_pred
```
```{r}
theme_vars <- c(
  "crush_theme", "empowerment_theme", "exes_theme", "forbidden_love_theme", 
  "grief_theme", "growing_up_theme", "growth_theme", "happy_theme", "hate_theme", 
  "heartbreak_theme", "jealousy_theme", "love_theme", "mental_health_theme", 
  "moving_on_theme", "partying_theme", "rebellion_theme", "religion_theme", 
  "reminiscing_theme", "revenge_theme", "situationship_theme", 
  "toxic_relationship_theme", "unrequited_theme"
)

prep_theme_df <- function(df, theme_name, theme_vars) {
  # Pull the theme column separately to ensure it's preserved
  target_theme_col <- df %>% select(all_of(theme_name))
  
  # Get numeric predictors, remove other theme variables
  df_numeric <- df %>%
    select(where(is.numeric)) %>%
    select(where(~ sum(., na.rm = TRUE) > 15)) %>%
    select(-any_of(setdiff(theme_vars, theme_name)))

  # Combine predictors with the target theme column
  df_clean <- bind_cols(df_numeric, target_theme_col) %>%
    drop_na(all_of(theme_name))
  
  return(df_clean)
}
theme_dfs <- lapply(theme_vars, function(theme) {
  prep_theme_df(df_num_full, theme, theme_vars)
})
names(theme_dfs) <- theme_vars

```


```{r}
crush <- lm(crush_theme ~ ., data = df_num_full_crush)
crush_backward_var <- ols_step_backward_p(crush)
#crush_backward_var
```


```{r}
empowerment <- lm(empowerment_theme ~ ., data = df_num_full_empowerment)
empowerment_backward_var <- ols_step_backward_p(empowerment)
summary(empowerment_backward_var$model)$coefficients %>%
  as.data.frame() %>%
  tibble::rownames_to_column("variable") %>%
  arrange(`Pr(>|t|)`)
```


```{r}
exes <- lm(exes_theme ~ ., data = df_num_full_exes)
exes_backward_var <- ols_step_backward_p(exes)
summary(exes_backward_var$model)$coefficients %>%
  as.data.frame() %>%
  tibble::rownames_to_column("variable") %>%
  arrange(`Pr(>|t|)`)
```
```{r}
forbidden_love <- lm(forbidden_love_theme ~ ., data = df_num_full_forbidden_love)
forbidden_love_backward_var <- ols_step_backward_p(forbidden_love)
summary(forbidden_love_backward_var$model)$coefficients %>%
  as.data.frame() %>%
  tibble::rownames_to_column("variable") %>%
  arrange(`Pr(>|t|)`)
```
```{r}
grief <- lm(grief_theme ~ ., data = df_num_full_grief)
grief_backward_var <- ols_step_backward_p(grief)
summary(grief_backward_var$model)$coefficients %>%
  as.data.frame() %>%
  tibble::rownames_to_column("variable") %>%
  arrange(`Pr(>|t|)`)
```



```{r}
# Extract coefficients summary and sort by p-value
summary(crush_backward_var$model)$coefficients %>%
  as.data.frame() %>%
  tibble::rownames_to_column("variable") %>%
  arrange(`Pr(>|t|)`)
```


```{r}
crush_backwards <- lm(crush_theme ~ Happy + Pop + word_baby + word_come + word_end + word_way +word_better+word_much+word_tell + Loud + word_want + word_still+word_like, df_num_full_crush)
#anova(crush_backwards)
#crush_backwards
df_num_full_pred$crush_pred <- predict(crush_backwards, newdata = df_num_full)

empowerment_backwards <- lm(empowerment_theme ~ Energy + word_turn + word_hold + word_hold + word_care + word_baby + word_know + word_never + Acoustic + word_now + word_life, df_num_full_empowerment)
#anova(empowerment_backwards)
#empowerment_backwards
df_num_full_pred$empowerment_pred <- predict(empowerment_backwards, newdata = df_num_full)
```


```{r}
exes_backwards <- lm(exes_theme ~ word_bad + word_keep + word_shes + word_leave + word_ever +  word_still + Happy + word_make + word_take , df_num_full_exes)
#anova(exes_backwards)
#exes_backwards

df_num_full_pred$exes_pred <- predict(exes_backwards, newdata = df_num_full)
```
```{r}
forbidden_love_backwards <- lm(forbidden_love_theme ~ word_mine + word_around + word_call + word_right + word_know + Pop + word_wanna + word_well + word_care + word_better + Dance + word_away + word_still + word_face, data = df_num_full_forbidden_love)
anova(forbidden_love_backwards)
forbidden_love_backwards
df_num_full_pred$forbidden_love_pred <- predict(forbidden_love_backwards, newdata = df_num_full)
```


```{r}
df_num_full_pred <- df_num_full_pred %>%
  mutate(
    # Find the name of the theme with the highest predicted score
    pred_max = pmax(crush_pred, situ_pred, unreq_pred, empowerment_pred, exes_pred, na.rm = TRUE),
    pred_theme = case_when(
      crush_pred == pred_max ~ "crush",
      situ_pred == pred_max ~ "situationship",
      unreq_pred == pred_max ~ "unrequited",
      empowerment_pred == pred_max ~ "empowerment",
      exes_pred == pred_max ~ "exes",
      forbidden_love_pred == pred_max ~ "forbidden love"
    ),
    
    # Find the actual theme that is active (1)
    actual_theme = case_when(
      crush_theme == 1 ~ "crush",
      situationship_theme == 1 ~ "situationship",
      unrequited_theme == 1 ~ "unrequited",
      empowerment_theme == 1 ~ "empowerment",
      exes_theme == 1 ~ "exes",
      forbidden_love_theme == 1 ~ "forbidden love"
    ),
    
    # Check if prediction matches actual theme
    correct_pred = pred_theme == actual_theme
  )

theme_accuracy <- df_num_full_pred %>%
  filter(!is.na(actual_theme)) %>%
  group_by(actual_theme) %>%
  summarise(
    accuracy = mean(correct_pred, na.rm = TRUE),
    n = n()
  ) %>%
  arrange(desc(accuracy))
accuracy <- mean(df_num_full_pred$correct_pred, na.rm = TRUE)
accuracy
theme_accuracy
```
```{r}
condense <- df_num_full_pred %>% 
  mutate(song = df$song_artist_id) %>%
  select(song, actual_theme, correct_pred, crush_pred, situ_pred, unreq_pred, empowerment_pred,exes_pred, forbidden_love_pred)
```

